{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime\n",
    "import json\n",
    "import re\n",
    "import os, gzip, shutil, fnmatch\n",
    "\n",
    "import sklearn\n",
    "import matplotlib\n",
    "from zipfile import BadZipfile\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Dataframe of Extracted Data from Daniel\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviceUsagePath = \"/Users/farhan/DNL/BuddingScholar/Budding_Scholar_22-23/ExtractedData/run1_sk_deviceUsage.csv\"\n",
    "keyboardPath = \"/Users/farhan/DNL/BuddingScholar/Budding_Scholar_22-23/ExtractedData/run1_sk_keyboard.csv\"\n",
    "surveyPath = \"/Users/farhan/DNL/BuddingScholar/Budding_Scholar_22-23/ExtractedData/run1_survey_results.csv\"\n",
    "\n",
    "device = pd.read_csv(deviceUsagePath).reset_index(drop=True)\n",
    "keyboard = pd.read_csv(keyboardPath).reset_index(drop=True)\n",
    "survey = pd.read_csv(surveyPath).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [col for col in keyboard.columns if (col.startswith(\"keyboard_sentiment\") or col.startswith(\"ParticipantIdentifier\") or col.startswith(\"trial_date\"))]\n",
    "sentimentDF = keyboard[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "##### Apple Sensorkit Sentiment Definitions:\n",
    "- case absolutist || A mood that embodies absolutism. = 0\n",
    "- case anger || A mood that embodies anger. = 4\n",
    "- case anxiety || A mood that embodies worrying. = 3\n",
    "- case confused || A mood that embodies confusion. = 9\n",
    "- case death || A mood that expresses death. = 2\n",
    "- case down || A mood that embodies depression. = 1\n",
    "- case health || A general concern for health. = 5\n",
    "- case lowEnergy A mood that indicates low energy. = 8\n",
    "- case positive || A mood that embodies positivity. = 6\n",
    "- case sad || A mood that embodies sadness. = 7\n",
    "___"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Path to raw data from myDataHelps\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/Users/farhan/DNL/BuddingScholar/Budding_Scholar_22-23/Data/\"\n",
    "metric_folder = \"sensorkit-keyboard-metrics/iPhone\"\n",
    "participant = \"2baee05a-5e5a-4436-8c25-2628d46d1e08/4684F36F-66CC-4FB1-9383-3BC2B008D365/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Helper Functions\n",
    "- Decompression\n",
    "- Date fixing\n",
    "- Formatting Data\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Iterative decompression\n",
    "from gzip import BadGzipFile\n",
    "\n",
    "\n",
    "def gz_extract(directory):\n",
    "    extension = \".gz\"\n",
    "    os.chdir(directory)\n",
    "    for item in os.listdir(directory): # loop through items in dir\n",
    "      if item.endswith(extension): # check for \".gz\" extension\n",
    "          gz_name = os.path.abspath(item) # get full path of files\n",
    "          file_name = (os.path.basename(gz_name)).rsplit('.',1)[0] #get file name for file within\n",
    "          try:\n",
    "            with gzip.open(gz_name,\"rb\") as f_in, open(file_name,\"wb\") as f_out:\n",
    "              # print(gz_name)\n",
    "              shutil.copyfileobj(f_in, f_out)\n",
    "            os.remove(gz_name) # delete zipped file\n",
    "          except BadZipfile:\n",
    "            continue\n",
    "          except BadGzipFile:\n",
    "            continue\n",
    "\n",
    "## returns a properly formatted word/emojiList\n",
    "def get_sentiment_list(emojiList: list):\n",
    "    returnList = [0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "    for i in [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]:\n",
    "      if (emojiList[i] == 0):\n",
    "        returnList[0] = int(emojiList[i + 1])\n",
    "      if (emojiList[i] == 1):\n",
    "        returnList[1] = int(emojiList[i + 1])\n",
    "      if (emojiList[i] == 2):\n",
    "        returnList[2] = int(emojiList[i + 1])\n",
    "      if (emojiList[i] == 3):\n",
    "        returnList[3] = int(emojiList[i + 1])\n",
    "      if (emojiList[i] == 4):\n",
    "        returnList[4] = int(emojiList[i + 1])\n",
    "      if (emojiList[i] == 5):\n",
    "        returnList[5] = int(emojiList[i + 1])\n",
    "      if (emojiList[i] == 6):  \n",
    "        returnList[6] = int(emojiList[i + 1])\n",
    "      if (emojiList[i] == 7):\n",
    "        returnList[7] = int(emojiList[i + 1])\n",
    "      if (emojiList[i] == 8):\n",
    "        returnList[8] = int(emojiList[i + 1])\n",
    "      if (emojiList[i] == 9):\n",
    "        returnList[9] = int(emojiList[i + 1])\n",
    "    return returnList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "def fix_date(end_date):\n",
    "    # if pd.to_datetime(end_date, format= '%Y-%m-%d', utc=True).hour < 5:\n",
    "    #     return pd.to_datetime(end_date, format= '%Y-%m-%d', utc=True).date() - datetime.timedelta(days=1)\n",
    "    # else:\n",
    "    #     return pd.to_datetime(end_date, format= '%Y-%m-%d', utc=True).date()\n",
    "    d = parser.parse(end_date)\n",
    "    return (d + datetime.timedelta(hours = -4)).date() # trial day associated with sample (4am is when the day flips)\n",
    "\n",
    "def get_date_from_timestamp(timestamp):\n",
    "    return pd.to_datetime(timestamp, format= '%Y-%m-%d', utc=True).date()\n",
    "\n",
    "def get_time_from_timestamp(timestamp):\n",
    "    return pd.to_datetime(timestamp, format= '%Y-%m-%d', utc=True).time()\n",
    "\n",
    "def set_am_pm(end_date):\n",
    "    if 5 < pd.to_datetime(end_date, format= '%Y-%m-%d', utc=True).tz_convert('US/Eastern').hour < 17:\n",
    "        return \"am\"\n",
    "    else:\n",
    "        return \"pm\"\n",
    "\n",
    "def average_corrections_am_pm_values(dataframe):\n",
    "\n",
    "    retroDF = dataframe.groupby(['name','ET_Date', 'am/pm'], as_index=False)[\"totalRetroCorrections\"].mean()\n",
    "    nearKeyDF = dataframe.groupby(['name','ET_Date', 'am/pm'], as_index=False)[\"totalNearKeyCorrections\"].mean()\n",
    "    SubstitutionDF = dataframe.groupby(['name','ET_Date', 'am/pm'], as_index=False)[\"totalSubstitutionCorrections\"].mean()\n",
    "    SpaceDF = dataframe.groupby(['name','ET_Date', 'am/pm'], as_index=False)[\"totalSpaceCorrections\"].mean()\n",
    "\n",
    "    correctionsDF = retroDF\n",
    "    correctionsDF = correctionsDF.merge(nearKeyDF, how='left', on=['name', 'ET_Date', 'am/pm'])\n",
    "    correctionsDF = correctionsDF.merge(SubstitutionDF, how='left', on=['name', 'ET_Date', 'am/pm'])\n",
    "    correctionsDF = correctionsDF.merge(SpaceDF, how='left', on=['name', 'ET_Date', 'am/pm'])\n",
    "\n",
    "    return correctionsDF\n",
    "\n",
    "def average_errors_am_pm_values(dataframe):\n",
    "\n",
    "    shortCharUP = dataframe.groupby(['name','ET_Date', 'am/pm'], as_index=False)[\"shortWordCharKeyUpErrorDistance\"].mean()\n",
    "    shortWordDown = dataframe.groupby(['name','ET_Date', 'am/pm'], as_index=False)[\"shortWordCharKeyDownErrorDistance\"].mean()\n",
    "    spaceUP = dataframe.groupby(['name','ET_Date', 'am/pm'], as_index=False)[\"spaceUpErrorDistance\"].mean()\n",
    "\n",
    "    errorDF = shortCharUP\n",
    "    errorDF = errorDF.merge(shortWordDown, how='left', on=['name', 'ET_Date', 'am/pm'])\n",
    "    errorDF = errorDF.merge(spaceUP, how='left', on=['name', 'ET_Date', 'am/pm'])\n",
    "\n",
    "    return errorDF\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Loop over raw data from myDataHelps to make an organized dataframe\n",
    "- Extracting totalWords and WordSentiments\n",
    "- Extracting totalEmojis and emojiSentiments\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop over all the exported data folders/directories\n",
    "from json import JSONDecodeError\n",
    "emojiSentimentList = []\n",
    "wordSentimentList = []\n",
    "\n",
    "for folder in os.listdir(directory):\n",
    "    path = directory + folder + \"/\" + metric_folder\n",
    "    \n",
    "    if folder == \".DS_Store\":\n",
    "        continue\n",
    "    \n",
    "    for participant in os.listdir(path):\n",
    "        ParticipantIdentifier = participant\n",
    "        pFolder = path + \"/\" + participant\n",
    "    \n",
    "        for data_folder in os.listdir(pFolder):\n",
    "            \n",
    "            final_path = pFolder + \"/\" + data_folder\n",
    "            \n",
    "            gz_extract(final_path)\n",
    "\n",
    "            ## print(path)\n",
    "            ## Loop over all files in this path/directory\n",
    "            for fname in os.listdir(final_path):\n",
    "                \n",
    "                filename = \"\"\n",
    "\n",
    "                ## name of the file\n",
    "                if fname.endswith(\"json\"):\n",
    "                    filename = final_path + \"/\" + fname\n",
    "                else: \n",
    "                    continue\n",
    "                \n",
    "                ## Load the JSON File\n",
    "                file = open(filename)\n",
    "                \n",
    "                # print(filename)\n",
    "                ## Need to use json.load and not json.loads\n",
    "                loaded_file = \"\"\n",
    "                \n",
    "                try:\n",
    "                    loaded_file = json.load(file)\n",
    "                except JSONDecodeError:\n",
    "                    continue\n",
    "\n",
    "                ## Get the samples list\n",
    "                samples = loaded_file[\"samples\"]\n",
    "\n",
    "                ## Get the name\n",
    "                name = loaded_file[\"device\"][\"name\"]\n",
    "\n",
    "                ## Need a loop here to iterate over all samples\n",
    "                for i in range(len(samples)):\n",
    "\n",
    "                    ## Get the TimeStamp for the current sample\n",
    "                    timeStamp = samples[i][\"timestamp\"]\n",
    "\n",
    "                    ## Get the sample dictionary\n",
    "                    sample_dict_iterator = samples[i][\"sample\"]\n",
    "\n",
    "                    ## Collect sentiment data from this sample\n",
    "                    totalWordsTemp = sample_dict_iterator[\"totalWords\"];\n",
    "                    totalEmojisTemp = sample_dict_iterator[\"totalEmojis\"];\n",
    "                    sentimentDict = sample_dict_iterator[\"sentimentMetrics\"];\n",
    "                    \n",
    "                    ## Collect the emoji sentiments\n",
    "                    emojiSentiments = sentimentDict[\"emojiCount\"];\n",
    "                    emojiCountList = get_sentiment_list(emojiSentiments)\n",
    "\n",
    "                    wordSentiments =  sentimentDict[\"wordCount\"]\n",
    "                    wordCountList =  get_sentiment_list(wordSentiments)\n",
    "\n",
    "\n",
    "                    emojiDictTemp = {\n",
    "                        \"name\": name,\n",
    "                        \"ParticipantIdentifier\": participant,\n",
    "                        \"TotalEmojis\": totalEmojisTemp,\n",
    "                        \"timeStamp\": timeStamp,\n",
    "                        \"emojiAbsolutionist\": emojiCountList[0], \"emojiAnger\": emojiCountList[4], \"emojiAnxiety\": emojiCountList[3], \n",
    "                        \"emojiConfused\": emojiCountList[9], \"emojiDeath\": emojiCountList[2], \"emojiDown\": emojiCountList[1],\n",
    "                        \"emojiHealth\": emojiCountList[5], \"emojiLowEnergy\": emojiCountList[8], \"emojiPositive\": emojiCountList[6],\n",
    "                        \"emojiSad\": emojiCountList[7]\n",
    "                    }\n",
    "\n",
    "                    wordDicttemp = {\n",
    "                        \"name\": name,\n",
    "                        \"TotalWords\": totalWordsTemp,\n",
    "                        \"ParticipantIdentifier\": participant,\n",
    "                        \"timeStamp\": timeStamp,\n",
    "                        \"wordAbsolutionist\": wordCountList[0], \"wordAnger\": wordCountList[4], \"wordAnxiety\": wordCountList[3], \n",
    "                        \"wordConfused\": wordCountList[9], \"wordDeath\": wordCountList[2], \"wordDown\": wordCountList[1],\n",
    "                        \"wordHealth\": wordCountList[5], \"wordLowEnergy\": wordCountList[8], \"wordPositive\": wordCountList[6], \n",
    "                        \"wordSad\": wordCountList[7]\n",
    "                    }\n",
    "\n",
    "                    emojiSentimentList.append(emojiDictTemp)\n",
    "                    wordSentimentList.append(wordDicttemp)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "- Create the emoji Sentiment Dataframe\n",
    "- Create the word Sentiment Dataframe\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojiSentimentDF = pd.DataFrame(emojiSentimentList)\n",
    "wordSentimentDF = pd.DataFrame(wordSentimentList)\n",
    "\n",
    "# Get date\n",
    "emojiSentimentDF[\"trial_date\"] = emojiSentimentDF.apply(lambda x: fix_date(x[\"timeStamp\"]), axis=1)\n",
    "wordSentimentDF[\"trial_date\"] = wordSentimentDF.apply(lambda x: fix_date(x[\"timeStamp\"]), axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Sum samples pertaining to the same participant and trial date\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "emojis = emojiSentimentDF.groupby(['trial_date', 'ParticipantIdentifier', 'name'], as_index =False).sum()\n",
    "words = wordSentimentDF.groupby(['trial_date', 'ParticipantIdentifier', 'name'], as_index =False).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Filter for a certain emoji and word count\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis = emojis.loc[emojis['TotalEmojis'] >= 15]\n",
    "## words = words.loc[words['TotalWords'] >= 200]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Load the affect DF\n",
    "- Which is created to raw data from myDataHelps using the self_report.ipynb notebook\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "affectDF = pd.read_csv(\"/Users/farhan/DNL/BuddingScholar/Budding_Scholar_22-23/output_tables/self_report.csv\")\n",
    "## Only keep affect scores in df\n",
    "col = [x for x in affectDF.columns if not x.endswith(\"gap\")]\n",
    "affectDF = affectDF[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "affectDF['trial_date'] = affectDF['trial_date'].astype(str)\n",
    "emojis['trial_date'] = emojis['trial_date'].astype(str)\n",
    "words['trial_date'] = words['trial_date'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_date</th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>name</th>\n",
       "      <th>TotalWords</th>\n",
       "      <th>wordAbsolutionist</th>\n",
       "      <th>wordAnger</th>\n",
       "      <th>wordAnxiety</th>\n",
       "      <th>wordConfused</th>\n",
       "      <th>wordDeath</th>\n",
       "      <th>wordDown</th>\n",
       "      <th>wordHealth</th>\n",
       "      <th>wordLowEnergy</th>\n",
       "      <th>wordPositive</th>\n",
       "      <th>wordSad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>2022-10-14</td>\n",
       "      <td>90592e06-bcf6-4150-85b0-c5daf7e7569c</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>502</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     trial_date                 ParticipantIdentifier    name  TotalWords  \\\n",
       "503  2022-10-14  90592e06-bcf6-4150-85b0-c5daf7e7569c  iPhone         502   \n",
       "\n",
       "     wordAbsolutionist  wordAnger  wordAnxiety  wordConfused  wordDeath  \\\n",
       "503                  5          1            1             0          1   \n",
       "\n",
       "     wordDown  wordHealth  wordLowEnergy  wordPositive  wordSad  \n",
       "503         2           1              0             9        0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verifier = words.loc[words.ParticipantIdentifier == \"90592e06-bcf6-4150-85b0-c5daf7e7569c\"]\n",
    "verifier = verifier.loc[verifier.trial_date == \"2022-10-14\"]\n",
    "verifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "- Merge the affect and words DF\n",
    "- Merge the affect and emojis DF\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_date</th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>name</th>\n",
       "      <th>TotalWords</th>\n",
       "      <th>wordAbsolutionist</th>\n",
       "      <th>wordAnger</th>\n",
       "      <th>wordAnxiety</th>\n",
       "      <th>wordConfused</th>\n",
       "      <th>wordDeath</th>\n",
       "      <th>wordDown</th>\n",
       "      <th>...</th>\n",
       "      <th>SR_affect_pos_focused</th>\n",
       "      <th>SR_affect_pos_focused_am</th>\n",
       "      <th>SR_affect_pos_happy</th>\n",
       "      <th>SR_affect_pos_happy_am</th>\n",
       "      <th>SR_affect_pos_hopeful</th>\n",
       "      <th>SR_affect_pos_hopeful_am</th>\n",
       "      <th>SR_affect_pos_motivated</th>\n",
       "      <th>SR_affect_pos_motivated_am</th>\n",
       "      <th>SR_affect_pos_relaxedCalm</th>\n",
       "      <th>SR_affect_pos_relaxedCalm_am</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-02</td>\n",
       "      <td>14b58072-ae3b-491e-a8ca-207f0d27ccf6</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>4377</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-03</td>\n",
       "      <td>14b58072-ae3b-491e-a8ca-207f0d27ccf6</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>1298</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trial_date                 ParticipantIdentifier    name  TotalWords  \\\n",
       "0  2022-10-02  14b58072-ae3b-491e-a8ca-207f0d27ccf6  iPhone        4377   \n",
       "1  2022-10-03  14b58072-ae3b-491e-a8ca-207f0d27ccf6  iPhone        1298   \n",
       "\n",
       "   wordAbsolutionist  wordAnger  wordAnxiety  wordConfused  wordDeath  \\\n",
       "0                 40          6            8             0          7   \n",
       "1                 20          3            1             0          7   \n",
       "\n",
       "   wordDown  ...  SR_affect_pos_focused  SR_affect_pos_focused_am  \\\n",
       "0         8  ...                    NaN                       NaN   \n",
       "1         3  ...                    NaN                       NaN   \n",
       "\n",
       "   SR_affect_pos_happy  SR_affect_pos_happy_am  SR_affect_pos_hopeful  \\\n",
       "0                  NaN                     NaN                    NaN   \n",
       "1                  NaN                     NaN                    NaN   \n",
       "\n",
       "   SR_affect_pos_hopeful_am  SR_affect_pos_motivated  \\\n",
       "0                       NaN                      NaN   \n",
       "1                       NaN                      NaN   \n",
       "\n",
       "   SR_affect_pos_motivated_am  SR_affect_pos_relaxedCalm  \\\n",
       "0                         NaN                        NaN   \n",
       "1                         NaN                        NaN   \n",
       "\n",
       "   SR_affect_pos_relaxedCalm_am  \n",
       "0                           NaN  \n",
       "1                           NaN  \n",
       "\n",
       "[2 rows x 54 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_words = words\n",
    "final_df_emojis = emojis\n",
    "\n",
    "# final_df = final_df.merge(words, how='left', on=['ParticipantIdentifier', 'trial_date', 'name'])\n",
    "final_df_words = final_df_words.merge(affectDF, how='left', on=['ParticipantIdentifier', 'trial_date']).reset_index(drop=True)\n",
    "final_df_emojis = final_df_emojis.merge(affectDF, how='left', on=['ParticipantIdentifier', 'trial_date']).reset_index(drop=True)\n",
    "\n",
    "final_df_words.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Multi Level modelling\n",
    "- Fixed effects occur due to our independent variable\n",
    "- Random effects occur due to clustering of data\n",
    "    - We can treat effect due to our repeated measures variable as a random effect\n",
    "    - So in our case, we can treat our participants as a source of random effects in our model\n",
    "\n",
    "Random effects models can be randon slope, random intercept, or both\n",
    "- Random intercept only = The random effects introduce different intercepts amongst groups (most common)\n",
    "- Randon slope = The random effects introduce different slopes (not common)\n",
    "- Can have a model where the intercepts and slopes can both vary (best approach)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "- Use a multi level model with participant identifier as the grouping variable\n",
    "- Model most likely uses an analogue of random intercept method\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_random_intercept_model(dataframe, grouping_variable, independent_variable, dependent_variable):\n",
    "    col = [\"trial_date\", grouping_variable, independent_variable, dependent_variable]\n",
    "    specificDF = dataframe[col].dropna()\n",
    "    # print(specificDF)\n",
    "\n",
    "    description = \"\"\n",
    "    description = description + independent_variable + \" ~ \" + dependent_variable\n",
    "\n",
    "    md = smf.mixedlm(description, specificDF, groups=specificDF[grouping_variable])\n",
    "    mdf = md.fit()\n",
    "    return mdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "affect_measure_list = ['affect_neg_angry', 'affect_neg_ashamed', 'affect_neg_bored', 'affect_neg_depressed', \n",
    "               'affect_neg_embarrassed', 'affect_neg_frustrated', 'affect_neg_guilty', 'affect_neg_lazy',\n",
    "               'affect_neg_lonelyIsolated', 'affect_neg_nervousAnxious', 'affect_neg_sad', 'affect_neg_stressed',\n",
    "               'affect_pos_amused', 'affect_pos_appreciated', 'affect_pos_excited', 'affect_pos_focused', \n",
    "               'affect_pos_happy', 'affect_pos_hopeful', 'affect_pos_motivated', 'affect_pos_relaxedCalm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Find correlation between Total Words and Affect Measures\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalWordsxAffectCorrResults = []\n",
    "for item in affect_measure_list:\n",
    "    totalWordsxAffectCorrResults.append(fit_random_intercept_model(final_df_words, \"ParticipantIdentifier\", \"SR_\" + item, \"TotalWords\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Find correlation between Total Emojis and Affect Measures\n",
    "- Use a multi level model with participant identifier as the grouping variable\n",
    "- Model uses random intercept method\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalEmojisxAffectCorrResults = []\n",
    "for item in affect_measure_list:\n",
    "    totalEmojisxAffectCorrResults.append(fit_random_intercept_model(final_df_emojis, \"ParticipantIdentifier\", \"SR_\" + item, \"TotalEmojis\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Find correlation between emojiCounts sentiment metrics and Affect Measures\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojiSad_x_Affect_CorrResults = []\n",
    "for item in affect_measure_list:\n",
    "    emojiSad_x_Affect_CorrResults.append(fit_random_intercept_model(final_df_emojis, \"ParticipantIdentifier\", \"SR_\" + item, \"emojiSad\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojiAnger_x_Affect_CorrResults = []\n",
    "for item in affect_measure_list:\n",
    "    emojiAnger_x_Affect_CorrResults.append(fit_random_intercept_model(final_df_emojis, \"ParticipantIdentifier\", \"SR_\" + item, \"emojiAnger\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojiAnxiety_x_Affect_CorrResults = []\n",
    "for item in affect_measure_list:\n",
    "    emojiAnxiety_x_Affect_CorrResults.append(fit_random_intercept_model(final_df_emojis, \"ParticipantIdentifier\", \"SR_\" + item, \"emojiAnxiety\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojiHealth_x_Affect_CorrResults = []\n",
    "for item in affect_measure_list:\n",
    "    emojiHealth_x_Affect_CorrResults.append(fit_random_intercept_model(final_df_emojis, \"ParticipantIdentifier\", \"SR_\" + item, \"emojiHealth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojiConfused_x_Affect_CorrResults = []\n",
    "for item in affect_measure_list:\n",
    "    emojiConfused_x_Affect_CorrResults.append(fit_random_intercept_model(final_df_emojis, \"ParticipantIdentifier\", \"SR_\" + item, \"emojiConfused\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojiLowEnergy_x_Affect_CorrResults = []\n",
    "for item in affect_measure_list:\n",
    "    emojiLowEnergy_x_Affect_CorrResults.append(fit_random_intercept_model(final_df_emojis, \"ParticipantIdentifier\", \"SR_\" + item, \"emojiLowEnergy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojiPositive_x_Affect_CorrResults = []\n",
    "for item in affect_measure_list:\n",
    "    emojiPositive_x_Affect_CorrResults.append(fit_random_intercept_model(final_df_emojis, \"ParticipantIdentifier\", \"SR_\" + item, \"emojiPositive\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Find correlation between wordCounts sentiment metrics and Affect Measures\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordSad_x_Affect_CorrResults = []\n",
    "# for item in affect_measure_list:\n",
    "#     wordSad_x_Affect_CorrResults.append(fit_random_intercept_model(final_df_words, \"ParticipantIdentifier\", \"SR_\" + item, \"wordSad\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordAnger_x_Affect_CorrResults = []\n",
    "for item in affect_measure_list:\n",
    "    wordAnger_x_Affect_CorrResults.append(fit_random_intercept_model(final_df_words, \"ParticipantIdentifier\", \"SR_\" + item, \"wordAnger\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordAnxiety_x_Affect_CorrResults = []\n",
    "for item in affect_measure_list:\n",
    "    wordAnxiety_x_Affect_CorrResults.append(fit_random_intercept_model(final_df_words, \"ParticipantIdentifier\", \"SR_\" + item, \"wordAnxiety\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordHealth_x_Affect_CorrResults = []\n",
    "for item in affect_measure_list:\n",
    "    wordHealth_x_Affect_CorrResults.append(fit_random_intercept_model(final_df_words, \"ParticipantIdentifier\", \"SR_\" + item, \"wordHealth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordConfused_x_Affect_CorrResults = []\n",
    "# for item in affect_measure_list:\n",
    "#     wordConfused_x_Affect_CorrResults.append(fit_random_intercept_model(final_df_words, \"ParticipantIdentifier\", \"SR_\" + item, \"wordConfused\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordLowEnergy_x_Affect_CorrResults = []\n",
    "# for item in affect_measure_list:\n",
    "#     wordLowEnergy_x_Affect_CorrResults.append(fit_random_intercept_model(final_df_words, \"ParticipantIdentifier\", \"SR_\" + item, \"wordLowEnergy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Print the desired findings\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printer = totalWordsxAffectCorrResults ## Change this line to which model results need to be visualized\n",
    "for item in printer:\n",
    "    print(item.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Use pearson correlation to see correlations between variables within participant\n",
    "- To be done again\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('matplot': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "306fbe589209a2d0d5ac1a00bab7d8bd2133d67d0d7a0a1aa98f6462bf4ce77d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
